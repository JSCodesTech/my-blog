+++
authors = ["Jonas Steinhauser"]
title = "YOLO-basierte Objekterkennung"
date = "2025-02-24"
description = "Dieser Artikel behandelt die Fusion von Sensordaten zur Objekterkennung und -lokalisierung in Innenr√§umen. Aufbauend auf fr√ºheren Arbeiten an der RWU, die YOLOv7 und YOLOv8 auf dem YCB-Datensatz benchmarkten, erweitere ich die Analyse auf YOLOv9."
tags = [
"Scientific Project",
]
+++

# Servus üëã  

Aktuell besch√§ftige ich mich mit **Sensordatenfusion f√ºr die Objekterkennung und -lokalisierung in Innenr√§umen**. In diesem Blog dokumentiere ich meine Arbeit, Fortschritte und Herausforderungen.  

## Was ist YOLO?  

YOLO (**You Only Look Once**) ist eines der bekanntesten Algorithmen f√ºr Echtzeit-Objekterkennung. Im Gegensatz zu klassischen Methoden analysiert YOLO ein Bild nicht schrittweise, sondern verarbeitet es in einem einzigen Durchlauf durch ein neuronales Netzwerk. Das macht es extrem schnell und effizient ‚Äì ideal f√ºr Robotik, autonome Systeme und √úberwachung.  

Die neuesten Versionen, wie **YOLOv11**, bieten verbesserte Pr√§zision, Geschwindigkeit und Anpassungsf√§higkeit, was sie besonders interessant f√ºr **Sensordatenfusion und Innenraumlokalisierung** macht. Falls du tiefer in das Thema eintauchen m√∂chtest, schau dir diesen Artikel an: [Roboflow Guide zu YOLO-Modellen](https://blog.roboflow.com/guide-to-yolo-models/).  

## Benchmarking von YOLO auf dem YCB-Datensatz  

An der RWU wurde bereits ein Vergleich von **YOLOv7 und YOLOv8** auf dem **YCB-Datensatz** durchgef√ºhrt. Der Datensatz umfasst 77 Alltagsgegenst√§nde, die oft in der Robotik verwendet werden. Ziel war es, die beiden Modelle hinsichtlich Effizienz und Genauigkeit zu bewerten[^1].  

### Wichtige Erkenntnisse:  

- **Datensatz & Training:** Die Studie nutzte die **YCB-Video- und YCB-M-Datens√§tze** mit 21 Objekten und f√ºhrte zus√§tzlich das neue **Robot Domain Dataset (RDD)** mit 259 Bildern aus realistischen Umgebungen ein.  
- **Bewertungsmetriken:** Die Leistung wurde anhand der **MS COCO-Metrik (AP@[.5:.05:.95], mAP50, mAP75)** gemessen.  
- **Ergebnisse:**  
  - **YOLOv8** schnitt auf den **YCB-M- und YCB-Video-Datens√§tzen** besser oder gleich gut wie **YOLOv7** ab.  
  - **YOLOv7** war auf dem **RDD-Datensatz** √ºberlegen und konnte sich besser an neue Umgebungen mit variierenden Hintergr√ºnden und Lichtbedingungen anpassen.  
- **Fazit:** **YOLOv8** eignet sich gut f√ºr bekannte Datens√§tze, aber **YOLOv7** ist robuster in neuen Szenarien. Das macht es f√ºr reale Robotik-Anwendungen besonders spannend.  

Mein aktuelles Projekt baut auf dieser Forschung auf, wobei ich **YOLOv9** in das System integriere. Der n√§chste Schritt ist die Optimierung der Sensordatenfusion, um die Genauigkeit der Objekterkennung und -lokalisierung weiter zu verbessern.  

Ich freu mich, meine Fortschritte hier zu teilen. Bis bald!  

**Servus üëã**  

*Jonas*  

[^1]: Samuel Hafner, Markus Schneider, Benjamin St√§hle (2024). *Performance Comparison of YOLOv7 and YOLOv8 Using the YCB Datasets YCB-M and YCB-Video*. EasyChair Preprint 13111, Version 2. [https://easychair.org/publications/preprint/c3GK](https://easychair.org/publications/preprint/c3GK)
